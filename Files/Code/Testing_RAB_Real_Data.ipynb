{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac92f81",
   "metadata": {},
   "source": [
    "# Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8f4704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Installing libraries \"\"\"\n",
    "%pip install --quiet pandas==2.3.2 matplotlib==3.10.6 seaborn==0.13.2 scikit-learn==1.7.1 numpy==2.2.6 pyarrow==21.0.0\n",
    "%pip install --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b8257",
   "metadata": {},
   "source": [
    "# Importando bibliotecas (externas e próprias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566e1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing libraries \"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path so 'Modules' can be imported\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Our modules\n",
    "from Modules.evaluation.output_formatter import forecast_to_output\n",
    "from Modules.loading.plug_n_play import get_clean_data\n",
    "from Modules.loading.read_parquet import read_parquet_file \n",
    "from Modules.models.forecast import forecast_blind\n",
    "from Modules.models.make_dataset import SingleSeriesDataset, MultiSeriesDataset\n",
    "from Modules.models.NBeats import NBeatsBlock, NBeats\n",
    "from Modules.models.test import hard_test\n",
    "from Modules.models.test import soft_test\n",
    "from Modules.models.training import train_model\n",
    "from Modules.models.WMAPELoss import WMAPELoss\n",
    "from Modules.preprocessing.onehot import one_hot_encode_parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7650c",
   "metadata": {},
   "source": [
    "# Definição dos hiper-parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4bbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Defining hyper-parameters \"\"\"\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    # Neural Network Global Parameters\n",
    "    'input_size': 30,       # Number of past days to use as input\n",
    "    'output_size': 7,       # Number of future days to predict\n",
    "    'batch_size': 28,       # Batch size for training\n",
    "    'n_layers': 4,          # Number of layers in the N-BEATS model\n",
    "    'hidden_size': 128,     # Number of hidden units in each layer\n",
    "\n",
    "    # Training parameters\n",
    "    'learning_rate': 1e-3,  # Learning rate for the optimizer\n",
    "    'epochs': 100,          # Number of training epochs (iterations over the entire dataset)\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),  # Use GPU if available\n",
    "    'blind_horizon': 4,     # Number of days to exclude from the end of the training set for hard test\n",
    "    'split': 1,             # Proportion of data to use for training (1.0 for validation)\n",
    "    'seed': 42,             # Random seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f16a3",
   "metadata": {},
   "source": [
    "# Importação do Dataset\n",
    "\n",
    "É interessante dividir o treino em batches (mini-conjuntos de treino). Cada batch possui o tamanho de input size, seguindo a ordem cronológica de vendas dentro daquela janela de dias. No entanto, durante o treinamento é **ESSENCIAL** que a escolha do próximo batch seja aleatória.\n",
    "\n",
    "Ex.: Inicia o treino por 21-27 jul e prevê 28, depois pula para 02-08 fev para prever 03. Esse processo deve ser repetido até todos os dados serem treinados, finalizando **01 epoch**.\n",
    "\n",
    "O número de **epochs** diz o número total de iterações do modelo com relação ao dataset inteiro.\n",
    "\n",
    "Sobre a composição da janela de input dentro de um batch, existem duas abordagens:\n",
    "\n",
    "1) Treinar em cada janela todas as séries (pense que cada par produto-loja x tempo representa uma série temporal dentro daquele período). Esse modelo é bem mais complexo pois o output deve ter o mesmo tamanho de produto-loja.\n",
    "2) Treinar vários modelos separados (considerando uma série temporal para cada modelo). Esse método é ineficiente pois o modelo nunca irá aprender os padrões entre as séries.\n",
    "3) Treinar o modelo com um par produto-loja por vez. Ou seja:\n",
    "   - O modelo realiza epochs = N iterações de treino ao longo de todo dataset\n",
    "     - Em cada epoch, passa por todas as M batches\n",
    "       - Em cada batch (que possui uma janela de tamanho input_size), atualiza os parâmetros para cada série temporal ($x_l,y_l$). Totalizando L atualizações, com L sendo o número de pares produto-loja.\n",
    "\n",
    "Ressalta-se que cada conjunto ($x_l,y_l$) representa:\n",
    "- $x_l$: série temporal do l-ésimo par produto-loja, sendo um vetor de tamanho input_size x (features + 1)\n",
    "- $y_l$: Previsão de vendas do l-ésimo par produto-loja para os próximos $output_size$ dias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6388577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:103 FILE_PATHS\n",
      "00:00:000 loaded_data\n",
      "00:03:416 numerical_table\n",
      "00:00:927 outlierless\n",
      "00:01:438 pivoted_df\n",
      "00:20:876 rescaled_df\n",
      "00:30:624 copying\n",
      "00:01:605 returning\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Recebe os dados filtrados / limpos \"\"\"\n",
    "\n",
    "clean_data = get_clean_data(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2a1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get dataset function \"\"\"\n",
    "\n",
    "def get_dataset(sample, feature, hyperparams):\n",
    "    input_size = hyperparams['input_size']\n",
    "    output_size = hyperparams['output_size']\n",
    "\n",
    "    # Inicializando os vetores de entrada e os rótulos\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Número total de amostras (janelas diferentes) que podem ser extraídas\n",
    "    # de um mesmo sample\n",
    "    num_windows = len(sample) - input_size - output_size + 1\n",
    "    print(f\"Número total de janelas extraídas: {num_windows}\")\n",
    "    print(f\"Para janelas de tamanho {input_size} e previsão de {output_size} dias à frente.\")\n",
    "    # Extraindo janelas deslizantes\n",
    "    for i in range(num_windows):\n",
    "\n",
    "        X_window = sample[i:i+input_size]             # janela de entrada\n",
    "        feature_window = feature[i:i+input_size]      # janela de entrada\n",
    "\n",
    "        X_window = np.stack([X_window,feature_window], axis=1)  # shape = (input_size, 4)\n",
    "\n",
    "        y_window = sample[i+input_size:i+input_size+output_size]  # próximos dias da série\n",
    "\n",
    "        X.append(X_window)\n",
    "        y.append(y_window)\n",
    "\n",
    "    # Convertendo para arrays numpy e depois para tensores PyTorch\n",
    "    X = np.array(X)  # shape = [num_windows, input_size, num_features]\n",
    "    y = np.array(y)  # shape = [num_windows, output_size]\n",
    "    print()\n",
    "    print(\"O vetor de entrada  antes do flatten\")\n",
    "    print(f\"tem shape (num_windows, size_window, num_features): {X.shape}\")\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32)  # shape = [n_samples, input_size, 1]\n",
    "\n",
    "    y = torch.tensor(y, dtype=torch.float32)  # shape = [n_samples, 1]\n",
    "\n",
    "\n",
    "    dataset_full = SingleSeriesDataset(X, y)\n",
    "    return dataset_full, X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa342bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training Model \"\"\"\n",
    "\n",
    "def traininig_func(X_train, y_train, num_features, hyperparams):\n",
    "    # Adotando o dataset de treino\n",
    "    batch_size = hyperparams['batch_size']\n",
    "    input_size = hyperparams['input_size']\n",
    "    hidden_size = hyperparams['hidden_size']\n",
    "    output_size = hyperparams['output_size']\n",
    "    n_layers = hyperparams['n_layers']\n",
    "    device = hyperparams['device']\n",
    "    learning_rate = hyperparams['learning_rate']\n",
    "    epochs = hyperparams['epochs']\n",
    "    \n",
    "    num_features = num_features\n",
    "    \n",
    "    dataset = SingleSeriesDataset(X_train, y_train) \n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=False) # shuffle=False para séries temporais\n",
    "\n",
    "    # Inicialização do modelo N-BEATS (considerando X_train com num_features)\n",
    "    model = NBeats(input_size*num_features, hidden_size, output_size, n_layers).to(device)\n",
    "    model, criterion, optimizer = train_model(model, learning_rate, epochs, device, dataloader)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c68833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training Model \"\"\"\n",
    "\n",
    "def get_blind_prediction(model, X_train, hyperparams):\n",
    "    blind_horizon = hyperparams['blind_horizon']\n",
    "    device = hyperparams['device']\n",
    "    output_size = hyperparams['output_size']\n",
    "    split = hyperparams['split']\n",
    "\n",
    "    if split != 1.0:\n",
    "        print(\"Previsão cega não realizada, pois split < 1.0\")\n",
    "        return\n",
    "\n",
    "    blind_prediction = forecast_blind(model, X_train, blind_horizon, device, output_size)\n",
    "    return blind_prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d7f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Separando treino e validação \"\"\"\n",
    "\n",
    "def get_train_validation(dataset_full, X, y, hyperparams):\n",
    "    split = hyperparams['split']\n",
    "\n",
    "    X_test, y_test = None, None\n",
    "    X_train, y_train = None, None\n",
    "    \n",
    "    # Ponto de separação entre treino e validação (Caso seja para envio, não há validação)\n",
    "    if split < 1:\n",
    "        split_point = int(split * len(dataset_full))\n",
    "        # Separação cronológica das janelas\n",
    "        X_train, X_test = X[:split_point], X[split_point:]\n",
    "        y_train, y_test = y[:split_point], y[split_point:]\n",
    "    else:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "\n",
    "    num_features = X_train.shape[2]\n",
    "    \n",
    "    # Flatten do tensor para entrar na rede\n",
    "    X_train = X_train.view(X_train.shape[0], -1)  # shape = [num_windows_train, input_size * n_features]\n",
    "\n",
    "    if split < 1:\n",
    "        X_test  = X_test.view(X_test.shape[0], -1) # shape = [num_windows_test, input_size * n_features]\n",
    "\n",
    "    print(f\"Há um total de {len(dataset_full)} janelas e o split ocorre em {split*100:.0f}% do dataset\")\n",
    "    print(f\" O shape de X_train é {X_train.shape} e o shape de X_test é {X_test.shape}\") if split < 1 else \"\"\n",
    "    print(f\" O shape de y_train é {y_train.shape} e o shape de y_test é {y_test.shape}\") if split < 1 else \"\"\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06621cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get Sample \"\"\"\n",
    "\n",
    "def get_sample(clean_data, col):\n",
    "    sample = clean_data[clean_data.sum().sort_values(ascending=True).index[-1]].values\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(clean_data)), sample)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607da96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create Feature and Rescale \"\"\"\n",
    "\n",
    "def create_feature_rescale(sampled): # Rescaling e sampling\n",
    "    sample = (sampled - np.min(sampled)) / (np.max(sampled) - np.min(sampled))\n",
    "    \n",
    "    feature = [sampled[t] - sampled[t-1] for t in range(1, len(sampled))]\n",
    "    feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature))\n",
    "    return sample, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87fdface",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(clean_data, prediction_col, hyperparams):\n",
    "    sample = get_sample(clean_data, prediction_col)\n",
    "    sample, feature = create_feature_rescale(sample)\n",
    "    dataset_full, X, y = get_dataset(sample, feature, hyperparams)\n",
    "    X_train, y_train, X_test, y_test, num_features = get_train_validation(dataset_full, X, y, hyperparams)\n",
    "    model = traininig_func(X_train, y_train, num_features, hyperparams)\n",
    "    blind_prediction = get_blind_prediction(model, X_train, hyperparams)\n",
    "    return blind_prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4622ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de janelas extraídas: 329\n",
      "Para janelas de tamanho 30 e previsão de 7 dias à frente.\n",
      "\n",
      "O vetor de entrada  antes do flatten\n",
      "tem shape (num_windows, size_window, num_features): (329, 30, 2)\n",
      "Há um total de 329 janelas e o split ocorre em 100% do dataset\n",
      "Epoch 1/100, Loss: 1.0764\n",
      "Epoch 2/100, Loss: 0.9884\n",
      "Epoch 3/100, Loss: 0.9363\n",
      "Epoch 4/100, Loss: 0.8400\n",
      "Epoch 5/100, Loss: 0.7201\n",
      "Epoch 6/100, Loss: 0.6633\n",
      "Epoch 7/100, Loss: 0.6355\n",
      "Epoch 8/100, Loss: 0.6168\n",
      "Epoch 9/100, Loss: 0.6075\n",
      "Epoch 10/100, Loss: 0.5987\n",
      "Epoch 11/100, Loss: 0.5911\n",
      "Epoch 12/100, Loss: 0.5704\n",
      "Epoch 13/100, Loss: 0.5553\n",
      "Epoch 14/100, Loss: 0.5521\n",
      "Epoch 15/100, Loss: 0.5436\n",
      "Epoch 16/100, Loss: 0.5301\n",
      "Epoch 17/100, Loss: 0.5275\n",
      "Epoch 18/100, Loss: 0.5233\n",
      "Epoch 19/100, Loss: 0.5105\n",
      "Epoch 20/100, Loss: 0.5061\n",
      "Epoch 21/100, Loss: 0.4956\n",
      "Epoch 22/100, Loss: 0.4842\n",
      "Epoch 23/100, Loss: 0.4852\n",
      "Epoch 24/100, Loss: 0.4652\n",
      "Epoch 25/100, Loss: 0.4590\n",
      "Epoch 26/100, Loss: 0.4582\n",
      "Epoch 27/100, Loss: 0.4501\n",
      "Epoch 28/100, Loss: 0.4507\n",
      "Epoch 29/100, Loss: 0.4498\n",
      "Epoch 30/100, Loss: 0.4248\n",
      "Epoch 31/100, Loss: 0.4172\n",
      "Epoch 32/100, Loss: 0.4174\n",
      "Epoch 33/100, Loss: 0.4184\n",
      "Epoch 34/100, Loss: 0.4079\n",
      "Epoch 35/100, Loss: 0.3951\n",
      "Epoch 36/100, Loss: 0.3974\n",
      "Epoch 37/100, Loss: 0.3713\n",
      "Epoch 38/100, Loss: 0.3738\n",
      "Epoch 39/100, Loss: 0.3819\n",
      "Epoch 40/100, Loss: 0.3851\n",
      "Epoch 41/100, Loss: 0.3795\n",
      "Epoch 42/100, Loss: 0.3656\n",
      "Epoch 43/100, Loss: 0.3600\n",
      "Epoch 44/100, Loss: 0.3374\n",
      "Epoch 45/100, Loss: 0.3449\n",
      "Epoch 46/100, Loss: 0.3737\n",
      "Epoch 47/100, Loss: 0.3781\n",
      "Epoch 48/100, Loss: 0.3672\n",
      "Epoch 49/100, Loss: 0.3800\n",
      "Epoch 50/100, Loss: 0.3636\n",
      "Epoch 51/100, Loss: 0.3576\n",
      "Epoch 52/100, Loss: 0.3398\n",
      "Epoch 53/100, Loss: 0.3325\n",
      "Epoch 54/100, Loss: 0.3147\n",
      "Epoch 55/100, Loss: 0.3197\n",
      "Epoch 56/100, Loss: 0.3027\n",
      "Epoch 57/100, Loss: 0.3014\n",
      "Epoch 58/100, Loss: 0.3140\n",
      "Epoch 59/100, Loss: 0.3263\n",
      "Epoch 60/100, Loss: 0.3218\n",
      "Epoch 61/100, Loss: 0.3140\n",
      "Epoch 62/100, Loss: 0.3222\n",
      "Epoch 63/100, Loss: 0.3125\n",
      "Epoch 64/100, Loss: 0.2938\n",
      "Epoch 65/100, Loss: 0.3103\n",
      "Epoch 66/100, Loss: 0.2949\n",
      "Epoch 67/100, Loss: 0.2693\n",
      "Epoch 68/100, Loss: 0.2692\n",
      "Epoch 69/100, Loss: 0.2660\n",
      "Epoch 70/100, Loss: 0.2683\n",
      "Epoch 71/100, Loss: 0.3072\n",
      "Epoch 72/100, Loss: 0.3090\n",
      "Epoch 73/100, Loss: 0.2854\n",
      "Epoch 74/100, Loss: 0.2696\n",
      "Epoch 75/100, Loss: 0.2628\n",
      "Epoch 76/100, Loss: 0.2435\n",
      "Epoch 77/100, Loss: 0.2492\n",
      "Epoch 78/100, Loss: 0.2761\n",
      "Epoch 79/100, Loss: 0.2575\n",
      "Epoch 80/100, Loss: 0.2568\n",
      "Epoch 81/100, Loss: 0.2302\n",
      "Epoch 82/100, Loss: 0.2144\n",
      "Epoch 83/100, Loss: 0.2036\n",
      "Epoch 84/100, Loss: 0.2118\n",
      "Epoch 85/100, Loss: 0.2069\n",
      "Epoch 86/100, Loss: 0.2117\n",
      "Epoch 87/100, Loss: 0.2490\n",
      "Epoch 88/100, Loss: 0.2545\n",
      "Epoch 89/100, Loss: 0.2423\n",
      "Epoch 90/100, Loss: 0.2207\n",
      "Epoch 91/100, Loss: 0.2069\n",
      "Epoch 92/100, Loss: 0.2123\n",
      "Epoch 93/100, Loss: 0.2268\n",
      "Epoch 94/100, Loss: 0.2306\n",
      "Epoch 95/100, Loss: 0.2290\n",
      "Epoch 96/100, Loss: 0.2271\n",
      "Epoch 97/100, Loss: 0.2196\n",
      "Epoch 98/100, Loss: 0.2202\n",
      "Epoch 99/100, Loss: 0.2049\n",
      "Epoch 100/100, Loss: 0.1891\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "semana",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pdv",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "produto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "quantidade",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "233fe0b5-89bf-4796-bc16-80f03fbe68ad",
       "rows": [
        [
         "0",
         "1",
         "1234",
         "4321",
         "1"
        ],
        [
         "1",
         "2",
         "1234",
         "4321",
         "1"
        ],
        [
         "2",
         "3",
         "1234",
         "4321",
         "1"
        ],
        [
         "3",
         "4",
         "1234",
         "4321",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semana</th>\n",
       "      <th>pdv</th>\n",
       "      <th>produto</th>\n",
       "      <th>quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "      <td>4321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1234</td>\n",
       "      <td>4321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1234</td>\n",
       "      <td>4321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1234</td>\n",
       "      <td>4321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   semana   pdv produto  quantidade\n",
       "0       1  1234    4321           1\n",
       "1       2  1234    4321           1\n",
       "2       3  1234    4321           1\n",
       "3       4  1234    4321           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Modularizando o código de predição \"\"\"\n",
    "\n",
    "prediction_col = ('1234', '4321')\n",
    "\n",
    "predictions = get_predictions(clean_data, prediction_col, HYPERPARAMS)\n",
    "\n",
    "final_df = forecast_to_output(predictions, prediction_col)  # Exemplo de uso\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Sampling and plotting - OK\"\"\"\n",
    "\n",
    "sample = get_sample(clean_data, prediction_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f71577",
   "metadata": {},
   "source": [
    "# Transformando o Dataframe em um Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Rescaling e sampling - OK \"\"\"\n",
    "\n",
    "sample, feature = create_feature_rescale(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf39687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get dataset \"\"\"\n",
    "\n",
    "dataset_full, X, y = get_dataset(sample, feature, hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1109f2",
   "metadata": {},
   "source": [
    "# Separando os dados entre treino / validação\n",
    "\n",
    "Os dados serão separados na proporção 80% - treino / 20% validação. Para séries temporais, é usual que essa separação seja feita de forma cronológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Separando treino e validação \"\"\"\n",
    "\n",
    "X_train, y_train, X_test, y_test, num_features = get_train_validation(dataset_full, X, y, hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9145c17",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training \"\"\"\n",
    "\n",
    "model = traininig_func(X_train, y_train, num_features, hyperparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986ff61",
   "metadata": {},
   "source": [
    "# Sanity check do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Sanity Check - TO-DO\"\"\"\n",
    "\n",
    "# sanity_check_plot()\n",
    "\n",
    "# ===\n",
    "\n",
    "def sanity_check_plot(model, dataloader, device, output_size):\n",
    "    \"\"\"\n",
    "    Plota previsões vs ground truth no período de treino\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            preds = model(x)\n",
    "            \n",
    "            # Se seu modelo retorna (batch, output_size)\n",
    "            preds = preds.cpu().numpy().flatten()\n",
    "            y = y.cpu().numpy().flatten()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(y)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(all_targets, label=\"Ground truth\", linewidth=2)\n",
    "    plt.plot(all_preds, label=\"Previsões\", linewidth=2, alpha=0.7)\n",
    "    plt.title(\"Sanity check - Previsões vs Ground Truth (treino)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "sanity_check_plot(model, dataloader, device, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ef72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c436ce4",
   "metadata": {},
   "source": [
    "# Validação do modelo\n",
    "\n",
    "São feitos dois testes:\n",
    "\n",
    "- **Soft test:** Modelo  tenta fazer as previsões, mas não utiliza-as nas previsões futuras, utiliza sempre os *ground truth* como input\n",
    "- **Hard test:** Modelo tenta fazer as previsões, e utiliza $y_{i-1}$ para a previsão de $y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Validation - TO-DO \"\"\"\n",
    "\n",
    "# validate_model()\n",
    "\n",
    "# ===\n",
    "\n",
    "\" Validando o modelo quando o split é menor que 1\"\n",
    "if split < 1:\n",
    "    # Adotando o dataset de validação (soft)\n",
    "    dataset = SingleSeriesDataset(X_test, y_test)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=False) # shuffle=False para séries temporais\n",
    "\n",
    "    all_preds_S, all_targets_S, avg_loss_test_S = soft_test(model, dataloader, device, criterion)\n",
    "\n",
    "    # Validação hard - previsão cega das primeiras blind_horizon semanas\n",
    "    all_preds_H, all_targets_H, avg_loss_test_H = hard_test(model, X_train, y_train, y_test, split_point, device, criterion, blind_horizon, output_size)\n",
    "\n",
    "    \" Sanity check da validação do modelo (preds and targets)\"\n",
    "    all_preds_array = []\n",
    "    all_targets_array = []\n",
    "\n",
    "    # Convert lists to tensors before flattening\n",
    "    all_preds_tensor = torch.cat([t.unsqueeze(0) if t.dim() == 1 else t for t in all_preds_H], dim=0).flatten()\n",
    "    all_targets_tensor = torch.cat([t.unsqueeze(0) if t.dim() == 1 else t for t in all_targets_H], dim=0).flatten()\n",
    "\n",
    "    for t in all_preds_tensor:\n",
    "        all_preds_array.append(t.detach().numpy())\n",
    "    for t in all_targets_tensor:\n",
    "        all_targets_array.append(t.detach().numpy())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(all_targets_array, label=\"Ground truth\", linewidth=2)\n",
    "    plt.plot(all_preds_array, label=\"Previsões\", linewidth=2, alpha=0.7)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab971a0",
   "metadata": {},
   "source": [
    "# Previsão cega (quando split == 1)\n",
    "\n",
    "Previsão para envio para o hackathon das 4 primeiras semanas de janeiro/23. Utiliza todo o dataset como treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Blind prediction \"\"\"\n",
    "\n",
    "blind_prediction = get_blind_prediction(model, X_train, hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee228b",
   "metadata": {},
   "source": [
    "# Ponto de parada - RAB 18-09-25\n",
    "- Temporais (mais fáceis de pensar e implementar)\n",
    "- Categóricas (intrínsecas do produto ou da loja, como a categoria deles)\n",
    "- De localização (apenas se der tempo)\n",
    "\n",
    "Após termos feito isso, podemos então realizar normalização dos sinais, one hot encoding do que for viável e embedding de IDs etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
